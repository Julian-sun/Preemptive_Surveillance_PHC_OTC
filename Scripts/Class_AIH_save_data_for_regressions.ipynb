{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read packedges\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.testing as tm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.discrete.discrete_model as dm\n",
    "\n",
    "from patsy import dmatrices\n",
    "import statsmodels.graphics.tsaplots as tsa\n",
    "\n",
    "\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations, chain\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import re\n",
    "\n",
    "import functions\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pymannkendall as mk\n",
    "\n",
    "import math\n",
    "\n",
    "import trend_timeseries\n",
    "\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from pmdarima.preprocessing import FourierFeaturizer\n",
    "from pmdarima.datasets import load_wineind\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import early_warning_detection_functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aih = pd.read_parquet('/Users/julianeoliveira/Documents/github/Bivariate_Anomaly_Detection_Primary_Health_Care_Drug_Selling_ILI_surveillance/Results/data_manuscript_warning_aih_imed2.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aih = df_aih[(df_aih.year_week >= '2022-47') & (df_aih.year_week <= '2024-52')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data and identify trend from the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dfs = []\n",
    "\n",
    "for region in df_aih['co_imed'].unique():\n",
    "    # Select data for a specific municipality\n",
    "    set_imed = df_aih[df_aih['co_imed'] == region]\n",
    "\n",
    "    # Sort by the epidemiological week date column\n",
    "    set_imed = set_imed.sort_values(by='year_week')\n",
    "\n",
    "    # Calculate 4-week rolling means and rename columns\n",
    "    set_imed = set_imed.assign(aih_4 = set_imed['n'].rolling(window=4).mean())\n",
    "        \n",
    "    # Calculate lagged values\n",
    "    for lag in range(1, 4):\n",
    "        set_imed = set_imed.assign(**{f'aih_4_lag_{lag}': set_imed.aih_4.shift(lag)})\n",
    "            \n",
    "        # Fill NaN values with 0\n",
    "        set_imed = set_imed.fillna(0)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    lst_dfs.append(set_imed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run negative binomial regressions to identify trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle Negative Binomial regression\n",
    "def fit_negative_binomial(series_name):\n",
    "    if dta[series_name].isnull().all() or np.all(dta[series_name] == 0):\n",
    "        \n",
    "        return {\n",
    "                f'coef_negbi_{series_name}': 0,\n",
    "                f'std_err_negbi_{series_name}': 0,\n",
    "                f'z_negbi_{series_name}': 0,\n",
    "                f'p_values_negbi_{series_name}': 1,\n",
    "                f'IC_low_negbi_{series_name}': 0,\n",
    "                f'IC_high_negbi_{series_name}': 0,\n",
    "                f'trend_line_negbi_{series_name}': np.zeros(len(dta))\n",
    "                }\n",
    "    \n",
    "    else:\n",
    "        model = smf.glm(\n",
    "                formula=f'{series_name} ~ time_trend',\n",
    "                data=dta,\n",
    "                family=sm.families.NegativeBinomial(alpha=1)\n",
    "                ).fit()\n",
    "            \n",
    "        return {\n",
    "                f'coef_negbi_{series_name}': model.params['time_trend'],\n",
    "                f'std_err_negbi_{series_name}': model.bse['time_trend'],\n",
    "                f'z_negbi_{series_name}': model.tvalues['time_trend'],\n",
    "                f'p_values_negbi_{series_name}': model.pvalues['time_trend'],\n",
    "                f'IC_low_negbi_{series_name}': model.conf_int().loc['time_trend', 0],\n",
    "                f'IC_high_negbi_{series_name}': model.conf_int().loc['time_trend', 1],\n",
    "                f'trend_line_negbi_{series_name}': model.predict()\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_results = []  # Initialize an empty list to store the processed DataFrames\n",
    "\n",
    "for dta in lst_dfs:\n",
    "    # Add a time trend column\n",
    "    dta = dta.assign(time_trend=np.arange(len(dta)))\n",
    "\n",
    "    # Fit Negative Binomial regression and update DataFrame\n",
    "    negbi_serie = fit_negative_binomial('aih_4')\n",
    "        \n",
    "\n",
    "    dta = dta.assign(**negbi_serie)\n",
    "\n",
    "    # Append the processed DataFrame to the list\n",
    "    lst_results.append(dta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aih2 =  pd.concat(lst_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of regions with significant trend\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of regions with significant trend')\n",
    "df_aih2[df_aih2.p_values_negbi_aih_4 <= 0.05].co_imed.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friedman test to Test Seasonality Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def friedman_test(x, freq=None):\n",
    "    \"\"\"\n",
    "    Conducts a Friedman rank test for seasonality in a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: pandas Series or numpy array, the time series data.\n",
    "    - freq: int, the frequency of the time series.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Contains test statistic, p-value, and additional information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape into matrix form for Friedman test\n",
    "    rows = len(x) // freq\n",
    "    if rows < 2:\n",
    "        raise ValueError(\"Not enough data points for the specified frequency.\")\n",
    "    \n",
    "    x = x[:rows * freq]  # Truncate to fit matrix dimensions\n",
    "    data_matrix = np.reshape(x, (rows, freq))\n",
    "    \n",
    "    # Perform Friedman test\n",
    "    test_stat, p_value = friedmanchisquare(*data_matrix.T)\n",
    "    \n",
    "    # Output results\n",
    "    return {\n",
    "        \"test_stat\": test_stat,\n",
    "        \"p_value\": p_value,\n",
    "        \"rows\": rows,\n",
    "        \"columns\": freq\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for data in lst_results:\n",
    "\n",
    "    # Keep 'data' as a DataFrame\n",
    "    data = data.assign(dtrend_aih_negbi = data.aih_4 - data.trend_line_negbi_aih_4)\n",
    "    \n",
    "    # Convert 'dtrend_ivas_negbi' column to NumPy array for Friedman test\n",
    "    data_array = data['dtrend_aih_negbi'].to_numpy()\n",
    "\n",
    "    # Set period for decomposition\n",
    "    p = len(data_array) // 2\n",
    "\n",
    "    # Perform Friedman test\n",
    "    res_test = friedman_test(data.dtrend_aih_negbi.to_numpy(), freq= p)\n",
    "\n",
    "    # Ensure '*_4_sea' is not zero\n",
    "    data['aih_4_sea'] = data['aih_4'].to_numpy() + 1e-5  \n",
    "\n",
    "    # Perform seasonal decomposition\n",
    "    result = seasonal_decompose(\n",
    "        data.set_index('year_week')['aih_4_sea'], \n",
    "        model='multiplicative',  # Fixed spelling\n",
    "        period=p, \n",
    "        extrapolate_trend='freq'\n",
    "    )\n",
    "\n",
    "    # Store results back \n",
    "    data = data.assign(p_value_aih_negbi_friedman   = res_test['p_value'],\n",
    "                       test_stat_aih_negbi_friedman = res_test['test_stat'],\n",
    "                       seas_decom_aih=result.seasonal.to_numpy()\n",
    "                       )\n",
    "    lst.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aih2 =  pd.concat(lst, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of imediate regions with significant sezonality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of imediate regions with significant sezonality')\n",
    "df_aih2[df_aih2.p_value_aih_negbi_friedman <= 0.05].co_imed.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aih2.to_parquet('/Users/julianeoliveira/Documents/github/Bivariate_Anomaly_Detection_Primary_Health_Care_Drug_Selling_ILI_surveillance/Results/data_manuscript_warning_aih_imed_for_regre.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
